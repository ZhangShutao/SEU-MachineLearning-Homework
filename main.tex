\documentclass[10pt]{beamer}
\usepackage{xeCJK}
\usepackage{listings}
\usepackage{tikz}
\usepackage{subfigure}
\usepackage{color}
\usepackage[ruled,linesnumbered,titlenotnumbered,noend,vlined]{algorithm2e}
\usetikzlibrary{arrows,automata}

\renewcommand{\thealgocf}{}
\newcommand{\sgn}{\textrm{sgn}}

\usetheme[
%	sidebar, % é»˜è®¤ä¸æ˜¾ç¤ºåŒ…å«å¹»ç¯ç‰‡ç»“æ„çš„è¾¹æ¡†ã€‚å¦‚è®¾ç½®sidebaré€‰é¡¹ï¼Œåˆ™å‚è€ƒAAUæ¨¡æ¿æ˜¾ç¤ºå·¦è¾¹æ¡†
	footline,
	blue, % ä¸»è‰²è°ƒé»˜è®¤ä¸ºçº¢è‰²ï¼Œè‰²è°ƒå¯ä»¥é€‰æ‹©redå’Œblue
%	wide, % å¹»ç¯ç‰‡çš„é•¿å®½æ¯”é»˜è®¤ä¸º4:3ï¼Œå¦‚è®¾ç½®äº†wideé€‰é¡¹åˆ™ä¸º16:9
	hideallsubsections, % é»˜è®¤æ˜¾ç¤ºæ‰€æœ‰ç­‰çº§çš„æ ‡é¢˜ã€‚å¦‚è®¾ç½®äº†hideallsubsectionsï¼Œ
	                    % åˆ™ä¸æ˜¾ç¤ºå°èŠ‚æ ‡é¢˜
	mathserif, % é»˜è®¤å…¬å¼å­—ä½“æ˜¯é’åŒ–çš„ï¼Œå¦‚è®¾ç½®mathserifé€‰é¡¹åˆ™é‡‡ç”¨æ­£å¸¸çš„å…¬å¼å­—ä½“
%	english, % é»˜è®¤å¹»ç¯ç‰‡ç¯å¢ƒä¸ºä¸­æ–‡ï¼Œå¦‚è®¾ç½®englishé€‰é¡¹åˆ™é‡‡ç”¨è‹±æ–‡çš„ç« èŠ‚å’Œå›¾è¡¨ç¼–å·
	sectiontoc, % è®¾ç½®sectiontocé€‰é¡¹åˆ™åœ¨æ¯èŠ‚ï¼ˆsectionï¼‰ä¹‹å‰æ·»åŠ ä¸€ä¸ªæ‰€æœ‰èŠ‚çš„ç›®å½•ï¼Œ
	            % å¹¶æ ‡æ˜æœ¬èŠ‚åœ¨æ•´ä¸ªå¹»ç¯ç‰‡ä¸­çš„ä½ç½®ï¼Œä¸å»ºè®®å’Œ\partå±‚çº§ä¸€åŒä½¿ç”¨
]{SEUstyle}

\title[ç¬¬å››ç»„æŠ¥å‘Š]{å¼ºåŒ–å­¦ä¹ ä¸è§„åˆ’ \\ å¼ºåŒ–å­¦ä¹ åœ¨æ¸¸æˆä¸­çš„åº”ç”¨}
\author[å¼ èˆ’éŸ¬ et al.]{åˆ˜ç¿”~å´æ±Ÿæ’~å¼ èˆ’éŸ¬~èµµå€©éš†}
\institute[SEU CS Dept. Team 4]{ä¸œå—å¤§å­¦\ è®¡ç®—æœºç§‘å­¦ä¸å·¥ç¨‹å­¦é™¢\ ç¬¬4ç»„}

\begin{document}
	{\background
		\begin{frame}[plain,noframenumbering]
			\titlepage
		\end{frame}
	}

	\begin{frame}{æ€»ç›®å½•}
		ç¬¬Iéƒ¨åˆ† å¼ºåŒ–å­¦ä¹ ä¸è§„åˆ’
		\tableofcontents[part=1]
		ç¬¬IIéƒ¨åˆ† å¼ºåŒ–å­¦ä¹ åœ¨FPSæ¸¸æˆä¸­çš„åº”ç”¨
		\tableofcontents[part=2]
	\end{frame}

	\part{å¼ºåŒ–å­¦ä¹ ä¸è§„åˆ’}\label{part:rl-and-planning}
	
	\section{èƒŒæ™¯çŸ¥è¯†å›é¡¾}
	
	\subsection{é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹}
	
	\begin{frame}{é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹}{å®šä¹‰}
		\visible<1->{
			ä¸€ä¸ªé©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹æ˜¯ä¸€ä¸ªäº”å…ƒç»„$D = \langle S,A,P,r,\gamma \rangle$ï¼Œå…¶ä¸­
			\begin{description}
				\item[$S$] è¿‡ç¨‹ä¸­çš„çŠ¶æ€ï¼ˆstateï¼‰é›†åˆ
				\item[$A$] è¿‡ç¨‹ä¸­çš„åŠ¨ä½œï¼ˆactionï¼‰é›†åˆ
				\item[$P$] è½¬ç§»å‡½æ•°ï¼ˆtransition functionï¼‰$P(s, a, s')$å®šä¹‰ä¸º$S \times A \times S \rightarrow [0,1]$ï¼Œè¡¨ç¤ºåœ¨çŠ¶æ€$s$æ—¶é€‰æ‹©åŠ¨ä½œ$a$è¾¾åˆ°çŠ¶æ€$s'$çš„æ¦‚ç‡
				\item[$r$] å¥–åŠ±å‡½æ•°ï¼ˆreward functionï¼‰$r(s, a, s')$å®šä¹‰ä¸º$S \times A \times S \rightarrow \mathbb{R}$ï¼Œè¡¨ç¤ºåœ¨çŠ¶æ€$s$æ—¶é€‰æ‹©åŠ¨ä½œ$a$è¾¾åˆ°çŠ¶æ€$s'$æ—¶å¾—åˆ°çš„å¥–åŠ±
				\item[$\gamma$] æŠ˜æ‰£å› å­ï¼ˆdiscount factorï¼‰$\gamma \in [0,1]$
			\end{description}
		}
		
		\visible<2->{
			ç´¯ç§¯å¥–åŠ±çš„å®šä¹‰
			\begin{equation*}
			\sum^{\infty}_{t=0} {\gamma^t r(s_t, a_t, s_{t+1})}   
			\end{equation*}
		}
	\end{frame}

	\begin{frame}{é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹}{é—®é¢˜}
		\begin{description}
			\item<2->[é¢„æµ‹é—®é¢˜ï¼ˆPredictingï¼‰] å·²çŸ¥èµ·å§‹çŠ¶æ€ã€è½¬ç§»å‡½æ•°å’Œå†³ç­–ç­–ç•¥ï¼Œæ±‚åœ¨æ­¤æƒ…å†µä¸‹èƒ½å¤Ÿå¾—åˆ°çš„ç´¯ç§¯å¥–åŠ±çš„æœŸæœ›ï¼›
			\item<3->[è§„åˆ’é—®é¢˜ï¼ˆPlanningï¼‰] å·²çŸ¥èµ·å§‹çŠ¶æ€å’Œè½¬ç§»å‡½æ•°ï¼Œæ±‚ä½¿ç´¯ç§¯å¥–åŠ±çš„æœŸæœ›å€¼æœ€å¤§çš„å†³ç­–ç­–ç•¥ï¼›
			\item<4->[å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰] è½¬ç§»å‡½æ•°æˆ–å¥–åŠ±å‡½æ•°æœªçŸ¥ï¼Œæ±‚ä½¿ç´¯ç§¯å¥–åŠ±çš„æœŸæœ›å€¼æœ€å¤§çš„å†³ç­–ç­–ç•¥ã€‚
		\end{description}
	\end{frame}

	\begin{frame}{é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹}{è§„åˆ’ä¸å­¦ä¹ }
		\begin{figure}
			\centering
			\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=30cm,semithick,bend angle=40]
			\tikzstyle{every state}=[rectangle,font=\bfseries,fill=white,draw=none,text=black]
			\node (policy) at (0,0)           [state] {value/policy};
			\node (exper)  at (1*2,-1.732*2)  [state] {experience};
			\visible<1,3>{\node (model)  at (-1*2,-1.732*2) [state] {model};}
			
			\path (policy) edge [bend left] node {acting} (exper);
			\visible<1-2>{\path (exper)  edge [bend left] node {direct RL} (policy);}
			\visible<1,3>{\path (exper) edge [bend left] node {model learning} (model);}
			\visible<1,3>{\path (model)  edge [bend left] node {planning} (policy);}
			
			\only<1>{\node at (0,-5.5) [state] { };}
			\only<2>{\node at (0,-5.5) [state,text=red] {Model-Free RL};}
			\only<3>{\node at (0,-5.5) [state,text=red] {Model-Based RL};}
			\end{tikzpicture}
			\caption{å­¦ä¹ ã€è§„åˆ’å’Œæ‰§è¡Œä¹‹é—´çš„å…³ç³»\protect\cite{Sutton1998:RL-Introduction}}\label{fig:relation-in-RL}
		\end{figure}
	\end{frame}

	\subsection{Q-Learning}
	
	\begin{frame}{Q-Learning}{å®šä¹‰}
		\begin{itemize}
			\item<2-> Q-Learningæ˜¯ä¸€ç§off-policyçš„æ—¶åºå·®åˆ†å­¦ä¹ æ–¹æ³•
			\item<3-> Q-Learningçš„ç›®æ ‡æ˜¯å¾—åˆ°$Q^*$å‡½æ•°çš„ä¼°è®¡ï¼Œå³
			\[Q^*(s,a) = \max_{\pi}\mathbb{E}(R_t | s_t = t, a_t = a, \pi) \]
			\[Q^*(s,a) = \mathbb{E}\left[r_{t+1} + \gamma \max_{a' \in A(s)} Q^*(s_{t+1}, a') | s_t = s, a_t = a\right] \]
			\item<4-> Q-learningçš„å®šä¹‰ä¸º
			\[ Q(s_t, a_t) \gets Q(s_t, a_t) + \alpha \left[r_{t+1} + \gamma \max_{a \in A(s_{t+1})}Q(s_{t+1}, a) - Q(s_t, a_t) \right] \]
		\end{itemize}
	\end{frame}

	\begin{frame}{Q-Learning}{ç®—æ³•æè¿°}
		\begin{algorithm}[H]
			éšæœºåˆå§‹åŒ–$Q(s, a)$\;
			\ForEach{æ¯ä¸ªå‘¨æœŸï¼ˆepisodeï¼‰}{
				åˆå§‹åŒ–$s$\;
				\ForEach{å‘¨æœŸå†…çš„æ¯ä¸€æ­¥ï¼Œç›´åˆ°$s$ä¸ºç»ˆæ­¢çŠ¶æ€}{
					åˆ©ç”¨$Q$å‡½æ•°ä¸­è·å¾—çš„ç­–ç•¥ï¼ˆä¾‹å¦‚$\epsilon$-greedyï¼‰é€‰æ‹©çŠ¶æ€$s$æ—¶é‡‡å–çš„ç­–ç•¥\;
					æ‰§è¡Œ$a$ï¼Œè§‚å¯Ÿ$s'$å’Œ$r'$\;
					$Q(s_t, a_t) \gets Q(s_t, a_t) + \alpha [r_{t+1} + \gamma \max_{a}Q(s_{t+1}, a) - Q(s_t, a_t) ]$\;
				}
			}
			\caption{Q-Learning}\label{alg:q-learning}
		\end{algorithm}
	\end{frame}

	\begin{frame}{åŸºäºå¼ºåŒ–å­¦ä¹ çš„è§„åˆ’}{Q-Planning}
		
		\begin{figure}
			\centering
			\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=50cm,semithick]
			\tikzstyle{every state}=[rectangle,fill=white,draw=none,text=black,align=center]
				\visible<2->{
					\node (model0) at(0,2) [state] {model};
					\node (policy0) at(9,2) [state] {policy};
					
					\path (model0) edge node {planning} (policy0);
				}
			
				\visible<3-> {
					\draw [->>,thick,draw=red] (4.5,1.5) -- (4.5,0.8);
					\node (model) at(0,0) [state] {model};
					\node (exper) at(3,0) [state] {simulated\\ experience};
					\node (values) at(6,0) [state] {values};
					\node (policy) at(9,0) [state] {policy};
					
					\path (model) edge (exper)
					(exper) edge node {backups} (values)
					(values) edge (policy);
				}
			\end{tikzpicture}
		\end{figure}
	
		\visible<4->{
			\begin{algorithm}[H]
				\Repeat{stop}{
					éšæœºé€‰æ‹©$s \in S$, $a \in A(s)$\;
					æ ¹æ®æ¨¡å‹æ¨¡æ‹Ÿå‡ºä¸‹ä¸€çŠ¶æ€$s'$å’Œå¥–åŠ±$r$\;
					æ›´æ–°$Q(s,a) \gets Q(s,a) + \alpha[r + \gamma \max_{a'}Q(s',a') - Q(s,a)]$\;
				}
				\caption{éšæœºQ-Planning}
			\end{algorithm}
		}
		
	\end{frame}

	\begin{frame}{å¼ºåŒ–å­¦ä¹ }{å¼ºåŒ–å­¦ä¹ çš„ä¸¤ç§æ–¹æ³•}
		\begin{small}		
			\begin{description}
				\item<2->[Model-Based RL] 
				
				ä¼˜ç‚¹ï¼š
				\begin{itemize}
					\item æœ‰æ—¶ç›´æ¥ä»ç¯å¢ƒä¸­å­¦åˆ°å€¼å‡½æ•°è¾ƒéš¾ï¼Œè€Œæ¨¡å‹çš„$P(sâ€™|s,a)$å’Œ$R(r|s,a)$å¾ˆå®¹æ˜“å°±èƒ½ç”¨ç›‘ç£å­¦ä¹ å»å­¦ï¼›
				\end{itemize}
				
				ç¼ºç‚¹ï¼š
				\begin{itemize}
					\item è¯¯å·®æ¥æºå¤šäº†æ¨¡å‹æ‹Ÿåˆçš„è¯¯å·®ï¼›
				\end{itemize}
				
				\item<3->[Model-Free RL] ä¼˜ç‚¹ï¼š
				\begin{itemize}
					\item ä¸éœ€è¦å…·ä½“çš„ç¯å¢ƒæ¨¡å‹ï¼›
					\item ä½¿ç”¨æ—¶åšå‡ºå†³ç­–çš„æ—¶é—´å¿«ï¼›
				\end{itemize}
				
				ç¼ºç‚¹ï¼š
				\begin{itemize}
					\item ä¼˜åŒ–è¿‡ç¨‹å¯èƒ½ä¸ç¨³å®šä¸”ä¸æ”¶æ•›ï¼›
					\item æ¯”è¾ƒéš¾é€‚åº”å˜åŒ–çš„ç¯å¢ƒï¼›
				\end{itemize}
			\end{description}
		\end{small}
	\end{frame}

	\begin{frame}{å¼ºåŒ–å­¦ä¹ }{Model-Free or Model-Based?}
		All models are wrong, but some are useful.
		\begin{flushright}
			--George E.P. Box, Robustness in the strategy of scientific model building
		\end{flushright}
	
		\begin{figure}
			\centering
			\begin{tikzpicture}
				\visible<2->{\node at (0,0) {\includegraphics[width=.4\linewidth]{pictures/newton.png}};}
				\visible<3->{\node at(2,0) {\includegraphics[width=.5\linewidth]{pictures/einstein.png}};}
				\visible<4->{\node at(4,0) {\includegraphics[width=.4\linewidth]{pictures/cat.png}};}
			\end{tikzpicture}
		\end{figure}
	\end{frame}

	\section{ä¸¤ç§è§„åˆ’ä¸å­¦ä¹ ç»“åˆçš„æ–¹æ³•}
	
	\subsection{Dyna}
	
	\begin{frame}{Dyna}{ä¸»è¦æ€æƒ³å’Œç»“æ„}
		\begin{figure}
			\centering
			\includegraphics[width=0.6\linewidth]{pictures/dyna-arch.png}
			\caption{Dyna agentçš„ä¸€èˆ¬ç»“æ„}
			\label{fig:dyna-arch}
		\end{figure}
		
		\begin{itemize}
			\item<2-> Dyna\cite{Sutton1990:Dyna}åŒ…æ‹¬äº†å›¾\ref{fig:relation-in-RL}ä¸­çš„æ‰€æœ‰è¿‡ç¨‹ï¼Œå³\alert{è§„åˆ’}ã€\alert{æ‰§è¡Œ}ã€\alert{æ¨¡å‹å­¦ä¹ }å’Œ\alert{å€¼å‡½æ•°å­¦ä¹ }
			\item<3-> è§„åˆ’æ—¶ä½¿ç”¨ä¸€ä¸ªç¡®å®šçš„æ¨¡å‹ï¼ˆå³$P(s,a,s') \rightarrow \{0,1\}$ï¼‰ï¼Œè¯¥æ¨¡å‹åœ¨ï¼›æ‰§è¡Œè¿‡ç¨‹ä¸­ä¸æ–­æ›´æ–°ï¼›
		\end{itemize}
	\end{frame}

	\begin{frame}{Dyna}{Dyna-Q}
		\begin{algorithm}[H]
			å¯¹ä»»æ„çš„$s \in S$ï¼Œ$a \in A(s)$ï¼Œåˆå§‹åŒ–$Q(s,a)$å’Œ$Model(s,a)$\;
			\Repeat{stop}{
				å¯¹å½“å‰çŠ¶æ€$s$ï¼Œæ ¹æ®$Q$è¡¨é€‰æ‹©$a \in A(s)$å¹¶æ‰§è¡Œï¼Œå¾—$s'$å’Œ$r$\;
				æ›´æ–°$Q(s,a)$\;
				\textcolor{blue}{ç”¨$s',r$æ›´æ–°$Model(s,a)$\;}
				\alert{
				\Repeat(\tcp*[f]{åœ¨$Model$ä¸Šè§„åˆ’å¹¶æ›´æ–°$Q$}){$N$æ¬¡å¾ªç¯}{
					$s$ä¸ºä»»æ„è§‚å¯Ÿåˆ°çš„çŠ¶æ€ï¼Œ$a$ä¸º$s$ä¸Šè¿›è¡Œè¿‡çš„ä»»æ„æ“ä½œ\;
					$s',r \gets Model(s,a)$\;
					$Q(s,a) \gets Q(s,a) + \alpha [r + \gamma\max_{a'}Q(s',a') - Q(s,a)]$\;
				}}
			}
			\caption{Dyna-Qç®—æ³•}\label{alg:dyna-q}
		\end{algorithm}
	\end{frame}

	\begin{frame}{Dyna}{å®éªŒ}
		\begin{figure}
			\centering
			\includegraphics[width=0.7\linewidth]{pictures/dyna-exp}
			\caption[Dnya-Q è¿·å®«]{Dyna-Qåœ¨ä¸€ä¸ªè¿·å®«é—®é¢˜ä¸Šçš„å®éªŒï¼Œagentéœ€è¦ä»Sèµ°åˆ°Gï¼Œ$r\rightarrow \{0,1\}$ã€‚å¯¹äºæ‰€æœ‰çš„$N$ï¼Œç¬¬ä¸€æ¬¡æ¢ç´¢æ˜¯ä¸€æ ·çš„ï¼Œéƒ½æ˜¯å¤§çº¦1700æ­¥ï¼›ä¹‹åï¼ŒDyna-Qå’ŒQ-Learningçš„å·®åˆ«å¼€å§‹æ˜¾ç°}
			\label{fig:dyna-exp}
		\end{figure}
	\end{frame}

	\begin{frame}{Dyna}{é”™è¯¯çš„æ¨¡å‹-åŸå› }
		æ¨¡å‹å‡ºé”™çš„åŸå› ï¼š
		\begin{itemize}
			\item å…ˆéªŒçŸ¥è¯†å­˜åœ¨é”™è¯¯
			\item éšæœºç¯å¢ƒéš¾ä»¥ç”¨æ¨¡å‹æè¿°æˆ–ä¼°è®¡
			\item ç¯å¢ƒå‡ºç°å˜åŒ–
		\end{itemize}
		
		å¤„ç†æ–¹æ³•ï¼šå­¦ä¹ è¿‡ç¨‹ä¸­ä¸æ–­ä½¿ç”¨ä»ç¯å¢ƒä¸­è·å¾—çš„æ•°æ®å¯¹æ¨¡å‹è¿›è¡Œæ›´æ–°å’Œçº æ­£
	\end{frame}
	
	\begin{frame}{Dyna}{é”™è¯¯çš„æ¨¡å‹-å®éªŒ}
		\begin{figure}
			\centering
			\includegraphics[width=0.5\linewidth]{pictures/blocking-maze}
			\caption{1000æ­¥ä¹‹åï¼Œè¿·å®«å‡ºç°å˜åŒ–ï¼Œå·¦ä¾§å¢™å£æ‰“å¼€ï¼Œå³ä¾§é€šè·¯å°é—­}
			\label{fig:blocking-maze}
		\end{figure}
		
		\visible<2->{
			\begin{figure}
				\centering
				\includegraphics[width=0.5\linewidth]{pictures/blocking-maze-result}
				\caption{ç”±äºDynaç®—æ³•åŒ…æ‹¬äº†å¯¹æ¨¡å‹çš„æ›´æ–°ï¼Œagentåœ¨ä¸€æ®µæ—¶é—´åå®Œæˆäº†å¯¹ç¯å¢ƒçš„é‡æ–°å»ºæ¨¡å¹¶æ‰¾åˆ°äº†æ­£ç¡®çš„è·¯å¾„ã€‚å›¾ä¸­Q+æ˜¯åŠ å¼ºäº†æ¢ç´¢èƒ½åŠ›çš„Q-Learningï¼Œç”¨$r+\kappa \sqrt{n}$ä¸ºå¥–åŠ±å‡½æ•°ï¼Œ$n$ä¸º$s$çŠ¶æ€ä¸‹$a$è¿ç»­æœªè¢«é€‰ä¸­çš„æ¬¡æ•°}
				\label{fig:blocking-maze-result}
			\end{figure}
		}
	\end{frame}
	
	\subsection{DARLING}
	
	\begin{frame}{DARLING}{æ–¹æ³•ä»‹ç»}
		DARLINGæ–¹æ³•\cite{Leonetti2016:AutoPlan-RL}çš„æ±‚è§£æ­¥éª¤ï¼š
		\begin{enumerate}
			\item<2-> æ ¹æ®é¢„è®¾çš„æ¨¡å‹ï¼Œç”¨è§„åˆ’æ±‚è§£å™¨ï¼ˆä¾‹å¦‚ASPæ¨ç†æœºï¼‰æ±‚è§£æŸä¸ªåº¦é‡å€¼ï¼ˆä¾‹å¦‚è§„åˆ’çš„æ­¥éª¤æ•°é‡ï¼‰åœ¨é˜ˆå€¼å†…çš„è§„åˆ’æ–¹æ¡ˆï¼›
			\item<3-> ç­›é€‰åˆå¹¶æ±‚å¾—çš„è§„åˆ’æ–¹æ¡ˆï¼Œåˆ é™¤åŒ…å«å†—ä½™æ­¥éª¤çš„æ–¹æ¡ˆï¼Œèåˆåå¾—åˆ°éƒ¨åˆ†ç­–ç•¥ï¼Œå³åœ¨å„ä¸ªçŠ¶æ€ä¸‹å¯é€‰çš„è¡ŒåŠ¨é›†åˆï¼›
			\item<4-> æ‰§è¡Œå’Œå­¦ä¹ ï¼Œåœ¨æ‰§è¡Œä¸­ä»…é€‰æ‹©éƒ¨åˆ†ç­–ç•¥ä¸­çš„è¡Œä¸ºï¼Œå­¦ä¹ å®ƒä»¬çš„ç´¯ç§¯å¥–åŠ±çš„æœŸæœ›å¹¶ä¼˜åŒ–ç­–ç•¥ã€‚
		\end{enumerate}
	
	\end{frame}

	\begin{frame}{DARLING}{å»ºæ¨¡ï¼Œè§„åˆ’ï¼Œç­›é€‰ï¼Œåˆå¹¶}
		\begin{description}
			\item<2->[å»ºæ¨¡ï¼ˆModelingï¼‰] å¯¹ç¯å¢ƒ$D=\langle S, A, P, r,\gamma \rangle$è¿›è¡Œå»ºæ¨¡ï¼Œå»ºç«‹ä»ç¯å¢ƒçŠ¶æ€åˆ°æ¨¡å‹çŠ¶æ€çš„å‡½æ•°$o:S \rightarrow S_m$ï¼Œå¾—$D_m = \langle S_m, A, P_m \rangle$ï¼Œå…¶ä¸­
			\item<3->[è§„åˆ’ï¼ˆPlanningï¼‰] åˆ©ç”¨è§„åˆ’å·¥å…·ï¼Œä»¥ä¸€å®šçš„å†—ä½™åº¦è®¡ç®—å¯è¡Œçš„æ–¹æ¡ˆã€‚è§„åˆ’æ˜¯åœ¨ä¸€ä¸ªå‡è®¾çš„æ¨¡å‹ä¸Šæ‰§è¡Œçš„ï¼Œå› æ­¤ä¸èƒ½ä¿è¯æ‰€å¾—çš„æ–¹æ¡ˆæ˜¯æœ€ä¼˜ç”šè‡³å¯è¡Œçš„ï¼›
			\item<4->[ç­›é€‰ï¼ˆFilteringï¼‰] å¦‚æœè§„åˆ’æ–¹æ¡ˆä¸­å­˜åœ¨é‡å¤å‡ºç°çš„çŠ¶æ€å’ŒåŠ¨ä½œï¼ˆä¾‹å¦‚å­˜åœ¨ç¯ï¼‰ï¼Œåˆ™è®¤ä¸ºæ–¹æ¡ˆæ˜¯å†—ä½™çš„ï¼Œå¯ä»¥è¢«æ›´çŸ­çš„æ–¹æ¡ˆä»£æ›¿ï¼›
			\item<5->[åˆå¹¶ï¼ˆMergingï¼‰] åˆå¹¶ç­›é€‰è¿‡çš„æ–¹æ¡ˆï¼Œå¾—åˆ°å¯è¾¾çŠ¶æ€å’Œè¿™äº›çŠ¶æ€ä¸‹å¯é€‰æ‹©çš„åŠ¨ä½œçš„é›†åˆï¼Œå³ä¸€ä¸ªç®€åŒ–çš„æ¨¡å‹$D_r$ï¼›
		\end{description}
		
		\vspace{10pt}
		\visible<5->{
			ä»Planningåˆ°Mergingçš„è¿‡ç¨‹å…¶å®æ˜¯å°†å‡è®¾ä¸­çš„æ¨¡å‹$D_m$åšäº†è¿›ä¸€æ­¥çš„åŒ–ç®€å’Œå‹ç¼©ã€‚
		}
	\end{frame}

	\begin{frame}{DARLING}{Planning \& Filtering and Merging-ä¾‹}
		\begin{figure}
			\centering
			\subfigure[è¿·å®«é—®é¢˜ï¼Œè¦æ±‚æœºå™¨äººä»Sèµ°åˆ°Gï¼Œå›¾ä¸­çº¢è‰²æ¨ªçº¿ä¸ºä¸€æ‰‡å¯èƒ½å¼€å¯æˆ–å…³é—­çš„é—¨ã€‚Planningæ­¥éª¤æ±‚é•¿åº¦å°äºæœ€çŸ­æ–¹æ¡ˆçš„1.5å€çš„æ–¹æ¡ˆ]{
			\includegraphics[width=0.475\linewidth]{pictures/grid-world.png}
			}
			\subfigure[éƒ¨åˆ†ç­–ç•¥ï¼Œç”±ç­›é€‰åçš„non-redudantæ–¹æ¡ˆèåˆè€Œæˆ]{
			\includegraphics[width=.35\linewidth]{pictures/partial-policy.png}
			}
			\label{fig:grid-world}
		\end{figure}
	
	\end{frame}

	\begin{frame}{DARLING}{Execution and learning}
		\begin{itemize}
		\item å®é™…çš„è½¬ç§»å‡½æ•°å’Œæ¨¡å‹ä¸­è®¾æƒ³çš„è½¬ç§»å‡½æ•°å¹¶ä¸ä¸€è‡´ã€‚è¿™ä¼šå¯¼è‡´agentåœ¨æ‰§è¡Œå’Œå­¦ä¹ çš„è¿‡ç¨‹ä¸­è¿›å…¥äº†æ¨¡å‹ä¸­æ²¡æœ‰çš„çŠ¶æ€ã€‚æ­¤æ—¶åº”è¯¥ä»¥æ–°å‡ºç°çš„çŠ¶æ€ä¸ºåˆå§‹çŠ¶æ€ï¼Œé‡æ–°è¿›è¡Œè§„åˆ’ï¼Œå¹¶å°†æ‰€å¾—çš„éƒ¨åˆ†ç­–ç•¥æ·»åŠ åˆ°å·²æœ‰çš„éƒ¨åˆ†ç­–ç•¥ä¸­ï¼›
		
		\item åœ¨æ‰€å¾—æ¨¡å‹ä¸Šçš„RLä¸å…¶ä»–çš„å¼ºåŒ–å­¦ä¹ å¹¶æ— å¤ªå¤§å·®åˆ«ï¼Œä»»æ„çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•éƒ½å¯ä»¥å®ç°ã€‚
		\end{itemize}
	\end{frame}

	\begin{frame}{DARLING}{å®éªŒ}
		\begin{itemize}
			\item<2-> å®éªŒé‡‡ç”¨çš„ç¯å¢ƒå¦‚å›¾\ref{fig:grid-world}æ‰€ç¤ºã€‚ä»…åœ¨agentåˆ°è¾¾é—¨å£æ—¶æ‰è·çŸ¥é—¨æ˜¯å¦æ‰“å¼€ï¼ˆPartial Observed MDPï¼ŒPOMDPï¼‰ï¼Œåœ¨å‘¨æœŸ$e$æ—¶é—¨æ‰“å¼€çš„æ¦‚ç‡ä¸º
				\[p(e)=
					\begin{cases}
						1 - \frac{e}{E-1} & 0 \leq e < E \\
						0 & \text{other wise}
					\end{cases}
				\]
			\item<3-> å®éªŒä¸­ç”¨åˆ°äº†ä»¥ä¸‹å‡ ç§agent:
			\begin{description}
				\item[P agent]<4-> ä»…åœ¨$D_m$ä¸Šè¿›è¡Œè§„åˆ’ï¼›
				\item[RL agent]<5-> ä»…åœ¨$D$ä¸Šè¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼›
				\item[PRL agent]<6-> é‡‡ç”¨DARLINGæ–¹æ³•ï¼Œåœ¨$D_m$ä¸Šè®¡ç®—éƒ¨åˆ†ç­–ç•¥ï¼Œå¹¶å°†å¼ºåŒ–å­¦ä¹ çš„æ¢ç´¢é™åˆ¶åœ¨$D_r$ä¸Šï¼›
				\item[Pmem-n agent]<7-> é‡‡ç”¨DARLINGæ–¹æ³•ï¼Œæœ‰å‰$n$ä¸ªå‘¨æœŸå†…è§‚å¯Ÿé—¨æ˜¯å¦æ‰“å¼€çš„è®°å¿†ï¼Œå¹¶ä»¥æ­¤ä¼°è®¡å½“å‰é—¨æ˜¯å¦æ‰“å¼€ï¼›
			\end{description}
		\end{itemize}
	\end{frame}

	\begin{frame}{DARLING}{å®éªŒç»“æœ}
		\begin{figure}
			\centering
			\includegraphics[width=0.6\linewidth]{pictures/darling-expr}
			\caption{å®éªŒç»“æœ}
			\label{fig:darling-expr}
		\end{figure}
		\visible<2->{
			\only<2>{P agentçš„ç´¯ç§¯å¥–åŠ±å˜åŒ–ä¸$p(e)$çš„æ¦‚ç‡ä¿æŒä¸€è‡´ã€‚ä½†ç”±äºå®é™…åº”ç”¨ä¸­ï¼Œ$D_m$å’Œ$D$å·®è·è¾ƒå¤§ï¼Œå› æ­¤ç›´æ¥ä½¿ç”¨è§„åˆ’æ–¹æ³•ä¸å¯èƒ½å–å¾—å¦‚æ­¤è‰¯å¥½çš„ç»“æœã€‚}
			\only<3>{RL agentå¾ˆå¿«å­¦åˆ°äº†æœ€ä¼˜ç­–ç•¥ï¼Œä½†ç¯å¢ƒå˜åŒ–åæ²¡æœ‰èƒ½å‘ç°æ›´ä¼˜çš„ç­–ç•¥ã€‚}
			\only<4>{PRL agentå­¦åˆ°äº†æœ€ä¼˜ç­–ç•¥ï¼Œå¹¶åœ¨ç¯å¢ƒå˜åŒ–åé€‰æ‹©äº†æ›´ä¼˜çš„ç­–ç•¥ã€‚}
			\only<5>{Pmem-1 agentè¢«èµ·åˆçš„è§‚å¯Ÿé™åˆ¶ï¼Œæ²¡æœ‰å‘ç°ç¯å¢ƒçš„å˜åŒ–ï¼Œå› æ­¤æ²¡æœ‰å‘ç°æ›´ä¼˜çš„ç­–ç•¥ã€‚å®é™…ä¸Šï¼Œæ— è®º$n$çš„å–å€¼å¦‚ä½•ï¼Œagentåœ¨ä¸ç¨³å®šçš„ç¯å¢ƒä¸­éƒ½æ²¡æœ‰è·å¾—æœ€ä¼˜ç­–ç•¥ã€‚}
		}
	\end{frame}

	\part{äº‹åç»éªŒå›æ”¾}\label{part:her}
	
	\section{ç›¸å…³èƒŒæ™¯}
	
	\begin{frame}{ç›¸å…³èƒŒæ™¯}{ç®€ä»‹}
		\begin{itemize}
			\item<2-> å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸ç¥ç»ç½‘ç»œçš„ç»“åˆè¢«å¹¿æ³›åº”ç”¨äºåºåˆ—å†³ç­–é—®é¢˜ä¸­ï¼›
			
			\item<3-> ä¸€ä¸ªå¿…é¡»è¦é¢å¯¹çš„é—®é¢˜ï¼ˆå°¤å…¶å¯¹äºæœºå™¨äººè®¾è®¡æ¥è¯´ï¼‰ï¼šé€šå¸¸éœ€è¦è®¾è®¡ä¸€ä¸ªå›æŠ¥å‡½æ•°ï¼ˆreward functionï¼‰ï¼Œå®ƒä¸ä»…è¦ä½“ç°ç›®æ ‡ä»»åŠ¡ï¼Œè€Œä¸”è¿˜è¦èƒ½å¤ŸæŒ‡å¯¼agentä¼˜åŒ–å†³ç­–ç­–ç•¥ï¼ˆpolicy optimizationï¼‰ï¼›
			
			\item<4-> ç”±æ­¤å¸¦æ¥çš„é—®é¢˜æ˜¯ï¼šè¿™ä¸ä»…éœ€è¦RLä¸“ä¸šçŸ¥è¯†ï¼Œè¿˜éœ€è¦é¢†åŸŸç‰¹å®šçš„çŸ¥è¯†ï¼ˆdomain-specific knowledgeï¼‰ï¼›
			
		\end{itemize}
		
		\visible<5>{Problemï¼šèƒ½å¦è®¾è®¡ä¸€ä¸ªç®—æ³•ï¼Œèƒ½å¤Ÿä»unshaped reward signalsï¼ˆe.g. ä¸€ä¸ª0-1 rewardè¡¨æ˜ä»»åŠ¡æ˜¯å¦æˆåŠŸå®Œæˆï¼‰ä¸­å­¦ä¹ ?}
	\end{frame}

	\begin{frame}{èƒŒæ™¯ä»‹ç»}{ç®€ä»‹}
		\begin{figure}
			\centering
			\begin{tikzpicture}
				\draw (0,0) rectangle (6cm, 4cm);
				\draw [draw=white] (4,3.5) node {Target Area};
				\draw (4,2) circle [radius=.75cm];
				\fill (1,2.5) circle [radius=.05cm,fill=black];
				\draw [->,>=stealth,draw=red] (1,2.5) -- (4,0.5);
				
				\visible<2->{\draw(4,1) circle [radius=.75cm];}
			\end{tikzpicture}
			\caption{äººç±»æ‹¥æœ‰çš„ä¸€ç§èƒ½åŠ›æ˜¯ä»æœªè¾¾åˆ°é¢„æœŸçš„ç»“æœé‚£é‡Œè·å¾—ä¸å¸Œæœ›è·å¾—çš„ç»“æœå‡ ä¹ä¸€æ ·çš„çŸ¥è¯†ã€‚}\label{fig:idea-of-her}
		\end{figure}
	\end{frame}

	\begin{frame}{ç›¸å…³èƒŒæ™¯}{Deep Q-Networks(DQN)}
		\begin{figure}
			\centering
			\includegraphics[width=0.4\linewidth]{pictures/DQN}
			\caption{ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥è¿‘ä¼¼Qå‡½æ•°ã€‚è¯¥ç½‘ç»œå°†ä¸€ä¸ªçŠ¶æ€sä½œä¸ºè¾“å…¥ï¼Œå¹¶ä¸ºæ¯ä¸ªåŠ¨ä½œaè¾“å‡ºQå‡½æ•°çš„ä¼°è®¡å€¼ã€‚}
			\label{fig:dqn}
		\end{figure}
	\end{frame}

	\begin{frame}{ç›¸å…³èƒŒæ™¯}{ç»éªŒå›æ”¾ï¼ˆExperience Replayï¼‰}
		\begin{itemize}
			\item å¯¹äºä¸å¯æšä¸¾çŠ¶æ€çš„ç¯å¢ƒï¼ˆå¦‚è¿ç»­çš„çŠ¶æ€ç©ºé—´ï¼‰ï¼Œä¸€èˆ¬é‡‡ç”¨å€¼å‡½æ•°é€¼è¿‘ï¼ˆValue Function Approxiamationï¼‰æ¥æ‹Ÿåˆå’Œæ³›åŒ–Qå‡½æ•°ã€‚
			
			\item ç»éªŒå›æ”¾ï¼ˆExperience replayï¼‰æ˜¯ä»ä¸€ä¸ªmemory poolä¸­éšæœºé€‰å–expeirenceæ›´æ–°ç½‘ç»œã€‚
			
			\item DQNæ˜¯åŸºäºç›‘ç£å­¦ä¹ çš„æ¡†æ¶ï¼Œè€Œloss functionåŸºäºRLï¼Œå› æ­¤ä¼šæœ‰è¿™æ ·çš„é—®é¢˜ï¼šç›‘ç£å­¦ä¹ éœ€è¦å‡è®¾æ ·æœ¬æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒï¼Œè€ŒRLä¸­çš„å¼ºåºåˆ—å…³è”æ€§ä¸ç¬¦åˆè¿™ä¸ªå‡è®¾ã€‚å¦‚æœæ²¡æœ‰experience replayï¼Œå¯èƒ½ä¼šå‡ºç°ä¸æ”¶æ•›çš„æƒ…å†µï¼›
			
			\item é‡‡ç”¨Experience Replayï¼Œä¼šç¼“å’Œæ ·æœ¬çš„å…³è”æ€§ã€‚å…¶ä¼˜ç‚¹åŒ…æ‹¬ï¼š
				\begin{enumerate}
					\item ç®—æ³•æ”¶æ•›ï¼›
					\item æé«˜æ³›åŒ–èƒ½åŠ›;
				\end{enumerate}
			
		\end{itemize}
	\end{frame}

	\begin{frame}{ç›¸å…³èƒŒæ™¯}{Deep Deterministic Policy Gradients (DDPG)}
		\begin{itemize}
			\item<2-> DQNæ˜¯ä¸€ä¸ªé¢å‘ç¦»æ•£æ§åˆ¶çš„ç®—æ³•ï¼Œå³è¾“å‡ºçš„åŠ¨ä½œæ˜¯ç¦»æ•£çš„ï¼›
			
			\item<3-> æ·±åº¦ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦ï¼ˆDeep Deterministic Policy Gradientï¼Œ DDPGï¼‰ç®—æ³•æ˜¯åˆ©ç”¨ DQN æ‰©å±• Q å­¦ä¹ ç®—æ³•çš„æ€è·¯å¯¹ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦ï¼ˆDeterministic Policy Gradientï¼Œ DPGï¼‰æ–¹æ³•è¿›è¡Œæ”¹é€ ï¼Œæå‡ºçš„ä¸€ç§åŸºäºè¡ŒåŠ¨è€…-è¯„è®ºå®¶ï¼ˆActor-Criticï¼ŒACï¼‰æ¡†æ¶çš„ç®—æ³•ï¼Œè¯¥ç®—æ³•å¯ç”¨äºè§£å†³è¿ç»­åŠ¨ä½œç©ºé—´ä¸Šçš„ DRL é—®é¢˜ã€‚
			
			\item<4-> éšæœºæ€§ç­–ç•¥å’Œç¡®å®šæ€§ç­–ç•¥ï¼š
				\begin{description}
					\item[éšæœºæ€§ç­–ç•¥]<5-> ç­–ç•¥è¾“å‡ºçš„æ˜¯åŠ¨ä½œçš„æ¦‚ç‡ï¼Œæ¯”å¦‚è¿ç»­åŠ¨ä½œæ§åˆ¶ï¼Œä½¿ç”¨çš„æ˜¯ä¸€ä¸ªæ­£æ€åˆ†å¸ƒå¯¹åŠ¨ä½œè¿›è¡Œé‡‡æ ·é€‰æ‹©ï¼Œå³æ¯ä¸ªåŠ¨ä½œéƒ½æœ‰æ¦‚ç‡è¢«é€‰åˆ°ï¼›
						\begin{description}
							\item[ä¼˜ç‚¹] å°†æ¢ç´¢å’Œæ”¹è¿›é›†æˆåˆ°ä¸€ä¸ªç­–ç•¥ä¸­ï¼›
							\item[ç¼ºç‚¹] éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®ï¼›
						\end{description}
					
					\item [ç¡®å®šæ€§ç­–ç•¥]<6-> ç­–ç•¥è¾“å‡ºå³æ˜¯åŠ¨ä½œ
						\begin{description}
							\item[ä¼˜ç‚¹] éœ€è¦é‡‡æ ·çš„æ•°æ®å°‘ï¼Œç®—æ³•æ•ˆç‡é«˜ï¼›
							\item[ç¼ºç‚¹] æ— æ³•æ¢ç´¢ç¯å¢ƒï¼›
						\end{description}
				\end{description}
			
		\end{itemize}
	\end{frame}
	
	\section{äº‹åç»éªŒå›æ”¾ï¼ˆHERï¼‰}
	
	\begin{frame}{HER}{å¯å‘æ¡ˆä¾‹-I}
		\begin{example}
			\begin{columns}
				\begin{column}{0.5\textwidth}
					\begin{itemize}
						\item ç¯å¢ƒæè¿°ï¼š
							\begin{description}
								\item[çŠ¶æ€ç©ºé—´] $S = \{0,1\}^n$
								\item[åŠ¨ä½œç©ºé—´] $\{0, 1, \dots, n-1 \}$
								\item[å¥–åŠ±å‡½æ•°] $r(s,a) = -\sgn(s \neq g)$
							\end{description}	
					\end{itemize}
					
				\end{column}
				\begin{column}{0.5\textwidth}
					\begin{figure}
						\includegraphics[width=.7\linewidth]{pictures/bit-flip.png}
						\caption{Bit Flippingå®éªŒç»“æœ}\label{fig:bi-flip}
					\end{figure}
				\end{column}
			\end{columns}
		
			\begin{tikzpicture}
				\node [draw opacity=0] (s) at (0,.5) {s:0100101010};
				\node [draw opacity=0] (g) at(0,0) {g:1101010100};
				\visible<3-> {
					\node [draw opacity=0,right of=s] (s1) at (3,.5) {\textcolor{red}{1}100101010};
					\path [->] (s) edge (s1);
				}
				\visible<2-> {
					\node [draw opacity=0] (a) at (2,.75) {Action:0};
				}
				\visible<4-> {
					\node [draw opacity=0] (r) at (2,.25) {Reward:-1};
				}
				\visible<5-> {
					\node [draw opacity=0] (v) at (6,.5) {};
					\path [->] (s1) edge node (dot) {$\cdots$} (v);
				}
			\end{tikzpicture}
		\end{example}
	\end{frame}

	\begin{frame}{HER}{å¯å‘æ¡ˆä¾‹-II}
		\begin{itemize}
			\item<2-> åœ¨è¿™æ ·çš„ç¯å¢ƒä¸‹ï¼Œå°¤å…¶æ˜¯æ¯”ç‰¹ä½æ•°$n$>40æ—¶ï¼Œç»å…¸çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•å¦‚DQNå¾ˆéš¾å­¦ä¹ åˆ°ä»èµ·å§‹çŠ¶æ€åˆ°ç»ˆç‚¹çŠ¶æ€çš„è·¯å¾„ï¼›å› ä¸ºå®ƒæ¢ç´¢åˆ°çš„rewardå€¼åŸºæœ¬éƒ½æ˜¯-1ï¼›
			
			\item<3-> åœ¨è¿™æ ·çš„ç¯å¢ƒä¸­ï¼Œä¸€ä¸ªæ¯”è¾ƒå¥½çš„è§£å†³æ–¹æ³•æ˜¯ç”¨ä¸€ä¸ªshaped reward functionï¼Œä»¥æ­¤æ¥ç»™äºˆagentæ›´å¤šåˆ°è¾¾ç»ˆç‚¹çš„ä¿¡æ¯ï¼›å¦‚ï¼š $r_g(s,a) = -||s - g||^2 $ï¼›
			
			\item<4-> åœ¨æ›´ä¸ºå¤æ‚çš„ç¯å¢ƒä¸­ï¼Œè®¾ç½®ä¸€ä¸ªæœ‰æ•ˆçš„åˆé€‚çš„å›æŠ¥å‡½æ•°æœ‰æ—¶ä¼šæ¯”è¾ƒå›°éš¾ï¼›å› æ­¤æœ¬æ–‡ç›®çš„æ˜¯è®¾è®¡ä¸€ä¸ªæ›´ä¸ºæ™®éçš„é€šç”¨äºå¤šç§ç¯å¢ƒä¸­çš„æ–¹æ³•ï¼Œè€Œä¸è¦æœ‰é’ˆå¯¹ç¯å¢ƒçš„ç‰¹å®šé¢†åŸŸçŸ¥è¯†ã€‚
			
		\end{itemize}
	\end{frame}

	\begin{frame}{HER}{å¤šç›®æ ‡å¼ºåŒ–å­¦ä¹ ï¼ˆMulti-goal RL ï¼‰}
		\begin{itemize}
			\item è®­ç»ƒagentèƒ½å¤Ÿå­¦ä¼šåˆ°è¾¾å¤šä¸ªç›®æ ‡ç‚¹ï¼›
				\[f_g \left( (x,y) \right) =  \sgn(s=g) \]
			
			\item ä½¿ç”¨Universal Value Function Approximatorsï¼Œåœ¨è®­ç»ƒpolicyå’Œvalue functionçš„è¿‡ç¨‹ä¸­ï¼Œå°†state $s$å’Œç›®æ ‡$g$ä½œä¸ºè¾“å…¥ï¼›
		\end{itemize}
		
	\end{frame}

	\begin{frame}{HER}{ç®—æ³•æè¿°}
		\begin{figure}
			\centering
			\begin{tikzpicture}[->,>=stealth',node distance=2cm]
				\node [state] (s0) {$s_0$};
				\node [state,right of=s0] (s1) {$s_1$};
				\node [state,right of=s1] (s2) {$s_2$};
				\node [state,right of=s2] (s3) {$s_3$};
				\node [state,right of=s3] (sr) {$s_r$};
				\path (s0) edge (s1)
						  (s1) edge (s2)
						  (s2) edge (s3)
						  (s3) edge node {$\cdots$} (sr);
			\end{tikzpicture}
		\end{figure}
	
		\begin{algorithm}[H]
			A episode: $s_0,s_1,s_2,â€¦, s_T$\;
			
			\ForEach{Time-stem $t$}{
				ä½¿ç”¨ç°æœ‰çš„ç­–ç•¥Aï¼Œä»ä¸­é€‰å–ä¸€ä¸ªaction$a_t$ï¼Œå³$a_t \gets \pi_b (s_t ||g)$\;
				è®¡ç®—rewardå€¼ï¼š$r_t=r(s_t,a_t,g)$\;
				Experience Replayï¼š å°†çŠ¶æ€è½¬ç§»$s_t \rightarrow s_(t+1)$ä»¥$(s_t ||g,a_t,r_t,s_(t+1)||g)$å½¢å¼ä¿å­˜åˆ°replay bufferä¸­\;
			}
			åˆ©ç”¨replay buffer è¿›è¡Œæ›´æ–°å·²æœ‰ç­–ç•¥A\;
			\caption{äº‹åç»éªŒå›æ”¾ç®—æ³•}\label{alg:her}
		\end{algorithm}
	\end{frame}
	
	\section{å®éªŒ}
	
	\begin{frame}{å®éªŒ}{ç¯å¢ƒ}
		\begin{itemize}
			\item é‡‡ç”¨åœ¨ç°æœ‰çš„ç¡¬ä»¶æœºå™¨äººçš„åŸºç¡€ä¸Šçš„æ§åˆ¶ç¯å¢ƒ
			\item å¯ç”¨ä¸€ä¸ªç‰©ç†å¼•æ“æ¨¡æ‹Ÿæœºå™¨äººçš„æ§åˆ¶å’Œåé¦ˆ
				\begin{figure}
					\centering
					\includegraphics[width=0.7\linewidth]{pictures/her-robot}
					\caption{ä¸‰ç§ä¸åŒçš„ä»»åŠ¡ï¼špushingï¼ˆç¬¬ä¸€è¡Œï¼‰ï¼Œslidingï¼ˆç¬¬äºŒè¡Œï¼‰ï¼Œpick and placeï¼ˆç¬¬ä¸‰è¡Œï¼‰}
					\label{fig:her-robot}
				\end{figure}
				
		\end{itemize}
	\end{frame}

	\begin{frame}{å®éªŒ}{ä¸‰ç§ä»»åŠ¡}
		\begin{description}
			\item[Pushing] A box is placed on a table in front of the robot and the task is to move it to the target location on the table. The robot fingers are locked to prevent grasping. The learned behavior is a mixture of pushing and rolling.
			
			\item[Sliding] A puck is placed on a long slippery table and the target position is outside of the robotâ€™s reach so that it has to hit the puck with such a force that it slides and then stops in the appropriate place due to friction.
			
			\item[Pick-and-place] The target position is in the air and the fingers are not locked. 
			
		\end{description}
	\end{frame}

	\begin{frame}{å®éªŒ}{æ¨¡å‹}
		\begin{description}
			\item[States] The state of the system is represented in the MuJoCo physics engine and consists of angles and velocities of all robot joints as well as positions, rotations and velocities (linear and angular) of all objects.
			
			\item[Goals] Goals describe the desired position of the object (a box or a puck depending on the task) with some fixed tolerance of $\epsilon$, i.e. , $f_g(s) = \sgn(g-s_{object} \leq \epsilon)$. 
			
			\item[Rewards] Use binary and sparse rewards $\{âˆ’1,0\}$;
			
			\item[State-goal distributions] For all tasks the initial position of the gripper is fixed, while the initial position of the object and the target are randomized;
			
		\end{description}
	\end{frame}
	
	\begin{frame}{å®éªŒ}{å¤šç›®æ ‡å­¦ä¹ ç»“æœ}
		\begin{figure}
			\centering
			\includegraphics[width=0.7\linewidth]{pictures/multi-goal-expr}
			\caption{å¤šç›®æ ‡å­¦ä¹ æ›²çº¿}
			\label{fig:multi-goal-expr}
		\end{figure}
		
	\end{frame}

	\begin{frame}{å®éªŒ}{å•ç›®æ ‡å­¦ä¹ ç»“æœ}
		\begin{figure}
			\centering
			\includegraphics[width=0.7\linewidth]{pictures/single-goal-expr}
			\caption{å•ç›®æ ‡å­¦ä¹ æ›²çº¿}
			\label{fig:single-goal-expr}
		\end{figure}
		
	\end{frame}

	\begin{frame}{å®éªŒ}{å¥–åŠ±å‡½æ•°å˜æ›´ç»“æœ}
		\begin{figure}
			\centering
			\includegraphics[width=0.7\linewidth]{pictures/reward-shape-expr}
			\caption{å˜æ›´å¥–åŠ±å‡½æ•°åçš„å­¦ä¹ æ›²çº¿ï¼Œå…¶ä¸­$r(s,a,g) = -|g-s'_{object}|^2$}
			\label{fig:reward-shape-expr}
		\end{figure}
		
	\end{frame}

	\section{ç»“è®º}
	
	\begin{frame}{ç»“è®º}
		\begin{enumerate}
			\item æå‡ºäº†HERç®—æ³•ï¼Œèƒ½å¤Ÿå°†å¼ºåŒ–å­¦ä¹ æ–¹æ³•åº”ç”¨åˆ°ç¨€ç–å›æŠ¥å€¼çš„é—®é¢˜ä¸­ï¼›
			\item HERç®—æ³•å…·æœ‰å¾ˆå¼ºçš„é€šç”¨æ€§ï¼Œèƒ½å¤Ÿç»“åˆä»»æ„çš„off-policy RLç®—æ³•ï¼Œåœ¨å®éªŒä¸­ç»“åˆçš„æ˜¯DQNå’ŒDDPGæ–¹æ³•ï¼›
			\item åœ¨å®éªŒä¸­ï¼Œå°†HERç®—æ³•åº”ç”¨åˆ°è®©æœºå™¨è‡‚å®Œæˆä¸åŒçš„ç§»åŠ¨ç‰©å“çš„ä»»åŠ¡ä¸Šï¼Œå±•ç¤ºäº†çªå‡ºçš„æ•ˆæœã€‚
		\end{enumerate}
	\end{frame}
		

	\part{DQN ä¸ DRQN}
	
	\section{èƒŒæ™¯çŸ¥è¯†}
	
	\begin{frame}{èƒŒæ™¯çŸ¥è¯†}{Atari 2600 games}
		\begin{columns}
			\begin{column}{.8\linewidth}
				\begin{itemize}
					\item é›…è¾¾åˆ©ï¼ˆ1972 ,ç¾å›½ï¼‰
					\item ä¸»è¦äº§å“ä¸ºAtari 2600æ¸¸æˆä¸»æœº
					\item æ¸¸æˆç¯å¢ƒ $\varepsilon$
					\begin{itemize}
						\item å±å¹•è¾“å‡º$x_t$
						\item agentæ‰§è¡Œçš„åŠ¨ä½œ$a_t$
						\item æ¸¸æˆåˆ†æ•°çš„å˜åŒ–$r_t$
						\item å±å¹•è¾“å‡ºä¸åŠ¨ä½œåºåˆ—è¡¨ç¤ºçŠ¶æ€$s_t$
						\[s_t=x_1,a_1,x_2,a_2,\dots,a_{t-1},x_t \]
						\item æœŸæœ›ç´¯ç§¯å¥–åŠ±
						\[R_t=\sum\nolimits_{t=t'}^{T}\gamma^{t-t'}r_{t'} \]
					\end{itemize}
					%\item é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹ % è¿™ä¸ªåœ¨è¿™é‡Œæ˜¯å¹²å•¥çš„ï¼Ÿ
				\end{itemize}
			\end{column}
			\begin{column}{.2\linewidth}
				\begin{figure}
					\centering
					\includegraphics[width=0.6\linewidth]{pictures/atari2600}
					\caption{Atari 2600}
					\label{fig:atari2600}
				\end{figure}
			\end{column}
		\end{columns}
	
		\vspace{-1em}
		\begin{figure}
			\centering
			\includegraphics[width=0.7\linewidth]{pictures/atari2600-games}
			\caption{Atari 2600ä¸Šçš„äº”ä¸ªæ¸¸æˆï¼Œåˆ†åˆ«æ˜¯Pongï¼ŒBreakoutï¼ŒSpace Invaderï¼ŒSeaquestï¼ŒBeam Rider}
			\label{fig:atari2600-games}
		\end{figure}
	\end{frame}

	\begin{frame}{èƒŒæ™¯çŸ¥è¯†}{Q-Learning}
		\begin{itemize}
			\item $Q^{\pi}(s,a)$å®šä¹‰ä¸ºä»çŠ¶æ€$s$å‡ºå‘ï¼Œæ‰§è¡ŒåŠ¨ä½œ$a$åï¼Œå†ä½¿ç”¨ç­–ç•¥$\pi$æ‰€å¾—åˆ°çš„ç´¯è®¡å¥–åŠ±
			\[Q^{\pi}(s,a) = E[R_t | s_t = s, a_t = a, \pi] \]
			
			\item $Q^*(s,a)$å®šä¹‰ä¸ºä»çŠ¶æ€$s$å‡ºå‘ï¼Œæ‰§è¡ŒåŠ¨ä½œ$a$åï¼Œå†ä½¿ç”¨æœ€ä¼˜ç­–ç•¥$\pi^*$å¾—åˆ°çš„æœ€ä¼˜ç´¯ç§¯å¥–åŠ±
			\[Q^*(s,a) = \max_{\pi}Q^{\pi}(s,a) \]
			
			\item agentçš„ç›®æ ‡å°±æ˜¯æ‰¾åˆ°æœ€ä¼˜ç­–ç•¥$\pi^*$
			
			\item å¦‚æœä¸‹ä¸€ä¸ªçŠ¶æ€$s'$å’Œå…¶æ‰€å¯¹åº”çš„æ‰€æœ‰åŠ¨ä½œ$a'$çš„æœ€ä¼˜å€¼å‡½æ•°$Q^*(s',a')$å·²çŸ¥ï¼Œé‚£ä¹ˆæ»¡è¶³è´å°”æ›¼ç­‰å¼
				\[Q^*(s,a) = \mathbb{E}_{s' \sim \epsilon}[r + \gamma \max_{a'}Q^*(s',a')|s,a] \]
			
			\item Q-Learningçš„å®šä¹‰ä¸ºï¼š
				\[ Q(s, a) \gets Q(s, a) + \alpha \left[r + \gamma \max_{a'}Q(s', a') - Q(s, a) \right] \]
		\end{itemize}
	\end{frame}

	\begin{frame}{èƒŒæ™¯çŸ¥è¯†}{Qå­¦ä¹ ç®—æ³•æè¿°}
		\begin{algorithm}[H]
			\KwIn{çŠ¶æ€ç©ºé—´$S$ï¼ŒåŠ¨ä½œç©ºé—´$A$ï¼ŒæŠ˜æ‰£ç‡$\gamma$ï¼Œå­¦ä¹ ç‡$\alpha$}
			\KwOut{ç­–ç•¥$\pi(s) = \arg\max_{a \in |A|}Q(s,a) $}
			éšæœºåˆå§‹åŒ–$Q(s,a)$\;
			$\forall s, \forall a, \pi(a|s) = \frac{1}{|A(s)|} $\;
			\Repeat{$\forall s, a$ï¼Œ$Q(s,a)$æ”¶æ•›}{
				åˆå§‹åŒ–èµ·å§‹çŠ¶æ€$s$\;
				\Repeat{$s$ä¸ºç»ˆæ­¢çŠ¶æ€}{
					åœ¨çŠ¶æ€$s$ï¼Œé€‰æ‹©$a \in \pi^{\epsilon}(s)$\;
					æ‰§è¡ŒåŠ¨ä½œ$a$ï¼Œå¾—åˆ°å³æ—¶å¥–åŠ±$r$å’Œæ–°çŠ¶æ€$s'$\;
					$Q(s, a) \gets Q(s, a) + \alpha \left[r + \gamma \max_{a'}Q(s', a') - Q(s, a) \right]$\;
					$s \gets s'$\;
				}
			}
			\caption{Qå­¦ä¹ ç®—æ³•}
		\end{algorithm}
	\end{frame}
	
	\section{DQN}
	
	\begin{frame}{DQN}{Why DQN}
		\begin{itemize}
			\item<2-> æ¸¸æˆä¸­çš„çŠ¶æ€æ•°é‡å¤ªå¤šï¼Œæ— æ³•éå†å’Œå­˜å‚¨æ‰€æœ‰çš„å€¼å‡½æ•°
			
			\item<3-> é€šå¸¸ä½¿ç”¨ä¸€ä¸ªå«å‚å‡½æ•°æ¥ä¼°è®¡å€¼å‡½æ•°
			
			\item<4-> å¼ºåŒ–å­¦ä¹ å¾ˆéš¾ä»é«˜ç»´æ•°æ®ï¼ˆä¾‹å¦‚è§†é¢‘ã€å£°éŸ³ï¼‰ä¸­ç›´æ¥å­¦ä¹ æ§åˆ¶ç­–ç•¥ã€‚è®¸å¤šåº”ç”¨äºè§†é¢‘å’Œå£°éŸ³é¢†åŸŸçš„å¼ºåŒ–å­¦ä¹ ç­–ç•¥éƒ½æ˜¯åŸºäºæ‰‹å·¥æŒ‡å®šçš„ç‰¹å¾
			
			\item<5-> æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œå¯ä»¥ç›´æ¥ä»è§†é¢‘ç­‰é«˜ç»´ä¿¡æ¯ä¸­å­¦ä¹ æŠ½è±¡çš„é«˜å±‚ç‰¹å¾
		\end{itemize}
	\end{frame}

	\begin{frame}{DQN}{Challenges in DQN}
		\begin{itemize}
			\item<2-> æ·±åº¦å­¦ä¹ æ–¹æ³•è¦æ±‚å¤§é‡äººå·¥æ ‡è®°çš„è®­ç»ƒæ•°æ®ã€‚å¼ºåŒ–å­¦ä¹ ç®—æ³•é€šå¸¸æ˜¯ä»æ•°å€¼å¥–åŠ±ä¸­å­¦ä¹ çš„ï¼Œè¿™äº›å¥–åŠ±åé¦ˆé€šå¸¸æ˜¯ç¨€ç–çš„ã€æœ‰å™ªå£°ã€æœ‰å»¶è¿Ÿçš„ã€‚
			
			\item<3-> å¤§å¤šæ•°æ·±åº¦å­¦ä¹ æ–¹æ³•å‡å®šæ•°æ®æ ·æœ¬æ˜¯ç‹¬ç«‹çš„ï¼Œç„¶è€Œå¼ºåŒ–å­¦ä¹ ç®—æ³•çš„æ•°æ®æ ·æœ¬é€šå¸¸æ˜¯å…·æœ‰é«˜åº¦ç›¸å…³æ€§çš„ã€‚
			
			\item<4-> åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œæ•°æ®æ ·æœ¬çš„åˆ†å¸ƒéšç€å­¦ä¹ åˆ°çš„ç­–ç•¥çš„æ”¹å˜è€Œæ”¹å˜ï¼Œè€Œæ·±åº¦å­¦ä¹ ä¸­å‡å®šæ•°æ®æ ·æœ¬çš„åˆ†å¸ƒæ˜¯å›ºå®šçš„
			
		\end{itemize}
	\end{frame}

	\begin{frame}{DQN}{Main Idea of DQN-I}
		\begin{itemize}
			\item è®­ç»ƒä¸€ä¸ªå‚æ•°ä¸º$\theta$çš„å·ç§¯ç¥ç»ç½‘ç»œæ¥ä¼°è®¡å€¼å‡½æ•°
			
			\item ä½¿ç”¨ç»éªŒå›æ”¾æ¥å‡å°‘æ•°æ®é—´çš„ç›¸å…³æ€§ï¼Œå¹³ç¼“æ•°æ®åˆ†å¸ƒçš„å˜åŒ–
			
			\item ä½¿ç”¨ä¸¤ä¸ªç½‘ç»œtarget Qä»¥åŠQç½‘ç»œï¼Œä¸¤ä¸ªç½‘ç»œç»“æ„ä¸€æ ·ï¼Œå‚æ•°ä¸åŒã€‚target Qç½‘ç»œçš„å‚æ•°$\theta_i^-$ï¼Œæ˜¯Qç½‘ç»œçš„å‚æ•°$\theta_i$çš„å†å²ç‰ˆæœ¬ã€‚Qç½‘ç»œçš„ä½œç”¨æ˜¯åœ¨æ¯æ¬¡è¿­ä»£ğ‘–ä¸­æ”¹å˜å‚æ•°$\theta_i$ï¼Œä¼°è®¡å€¼å‡½æ•°ã€‚target Qç½‘ç»œçš„ä½œç”¨æ˜¯ç»™å‡ºæ¯æ¬¡è¿­ä»£$i$ä¸­çš„ä¼°è®¡ç›®æ ‡
			\[y_i = E_(s' \in \epsilon)[r + \gamma \max_{a'} target\_Q(s',a',\theta_i^-)] \]
			
			\item æ¯æ¬¡è¿­ä»£ğ‘–çš„æŸå¤±å‡½æ•°å¯ä»¥è¡¨ç¤ºä¸º
			\[L_i(\theta_i) = E_{s,a,r,s'}[(y_i - Q(s,a| \theta_i))^2] \]
			
		\end{itemize}
	\end{frame}

	\begin{frame}{DQN}{Main Idea of DQN-II}
		\begin{itemize}
			\item target Qç½‘ç»œä½¿ç”¨Qç½‘ç»œçš„å‚æ•°$\theta_i$çš„å†å²ç‰ˆæœ¬èƒ½å¤Ÿå¹³ç¼“æ•°æ®åˆ†å¸ƒçš„å˜åŒ–
			
			\item ç¬¬$i$æ¬¡è¿­ä»£çš„æŸå¤±å‡½æ•°ä¸º
			\[L_i(\theta_i)=E_{s,a,r,s'}[(r + \gamma \max_{a'}target\_Q(s',a',\theta_i^-) - Q(s,a,\theta_i))^2] \]
			
			\item æ›´æ–°æ¢¯åº¦ä¸º
				\begin{small}
					\[\nabla_{\theta_i}L_i(\theta_I) = E_{s,a,r,s'}[(r + \gamma \max_{a'} target\_Q(s',a'|\theta_i^-) - Q(s,a|\theta_i))\nabla_{\theta_i}Q(s,a|\theta_i)] \]
				\end{small}
			
			\item ä¸Q-learningç›¸æ¯”
			\[ Q(s, a) \gets Q(s, a) + \alpha \left[r + \gamma \max_{a'}Q(s', a') - Q(s, a) \right] \]
			
		\end{itemize}
	\end{frame}

	\begin{frame}{DQN}{ç½‘ç»œç»“æ„}
		\begin{figure}
			\centering
			\includegraphics[width=0.8\linewidth]{pictures/dqn-architecture}
			\caption{}
			\label{fig:dqn-architecture}
		\end{figure}
		
	\end{frame}

	\section{DRQN}

	\begin{frame}{DQN}{ç»éªŒå›æ”¾}
		\begin{itemize}
			\item ç»´æŒä¸€ä¸ªæ•°é‡æœ‰é™çš„ç»éªŒæ± $D=e_1,\dots,e_t$
			
			\item æ¯æ¬¡agentåœ¨æ—¶é—´$t$è¡ŒåŠ¨åè·å¾—çš„ç»éªŒ$e_t = (s_t,a_t,r_t,s_{t+1})$å­˜å…¥ç»éªŒæ± $D$ä¸­
			
			\item åœ¨è®­ç»ƒæ—¶ï¼Œéšæœºåœ°ä»ç»éªŒæ± $D$ä¸­é€‰æ‹©ç»éªŒ$e_t$æ¥è®­ç»ƒç½‘ç»œ
			
		\end{itemize}
	\end{frame}
	
	\begin{frame}{DRQN}{ç®—æ³•}
		\begin{figure}
			\centering
			\includegraphics[width=0.9\linewidth]{pictures/drqn-alg}
			\caption{}
			\label{fig:drqn-alg}
		\end{figure}
	\end{frame}

	\begin{frame}{DRQN}{å®éªŒç»“æœ-I}
		\begin{figure}
			\centering
			\includegraphics[width=0.7\linewidth]{pictures/drqn-expr-result-tab}
			\caption{}
			\label{fig:drqn-expr-result-tab}
		\end{figure}	
	\end{frame}

	\begin{frame}{DRQN}{å®éªŒç»“æœ-II}
		\begin{figure}
			\centering
			\includegraphics[width=0.7\linewidth]{pictures/drqn-expr-result-chart}
			\caption{}
			\label{fig:drqn-expr-result-chart}
		\end{figure}
		
	\end{frame}
	
	\part{FPSæ¸¸æˆä¸DRQN}
	
	\section{DRQN}
	
	\begin{frame}{Deep Q-Network å›é¡¾}
		\begin{columns}
			\begin{column}{.6\linewidth}
				\begin{itemize}
					\item å‰é¢æåˆ°ï¼ŒDQNåœ¨Atariæ¸¸æˆä¸­ï¼Œæœ‰èƒ½åŠ›å­¦ä¹ åˆ°ä¸è¾“äººç±»çš„æ§åˆ¶ç­–ç•¥ã€‚
					\item å®ƒä»…ä»…å°†æ¸¸æˆæœ€è¿‘4å¸§çš„åŸå§‹ç”»é¢ä½œä¸ºè¾“å…¥ï¼Œå°±ä½¿agentåœ¨Atariæ¸¸æˆä¸­æœ‰äº†èƒ½ä¸äººç±»ç›¸æŠ—è¡¡çš„è¡¨ç°ã€‚
					\item ä½†æ˜¯ï¼ŒDQNåœ¨éœ€è¦è®°å¿†\alert{è¶…è¿‡æœ€è¿‘4å¸§}ç”»é¢çš„æ¸¸æˆä¸­è¡¨ç°ä¸ä½³ï¼Œè¿™ç±»æ¸¸æˆæœªæ¥çš„stateå’Œrewardä¸ä»…ä¾èµ–äºå½“å‰è¾“å…¥çš„ç”»é¢ï¼Œè¿˜ä¾èµ–äºæ›´æ—©ç”»é¢ä¸­çš„ä¿¡æ¯ã€‚
					\item ä¸Šè¿°ç°è±¡æ˜¯ä¸€ç§ Partially-Observable Markov Decision Process (POMDP)ã€‚
				\end{itemize}
			\end{column}
			\begin{column}{.4\linewidth}
				\begin{figure}
					\centering
					\includegraphics[width=0.9\linewidth]{pictures/dqn-architecture-2}
					\caption{}
					\label{fig:dqn-architecture-2}
				\end{figure}
				
			\end{column}
		\end{columns}
		
	\end{frame}

	\begin{frame}{ä»DQNåˆ°DRQN}
		ä¸ºè§£å†³å‰è¿°POMDPé—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦å¯¹åŸå§‹çš„DQNåŠ ä»¥æ”¹è¿›ï¼ŒDeep Recurrent Q-Networkåº”è¿è€Œç”Ÿã€‚
		\begin{columns}[c]
			\begin{column}{.4\linewidth}
				\begin{figure}
					\centering
					\includegraphics[width=0.9\linewidth]{pictures/dqn-architecture-2}
				\end{figure}
			\end{column}
			\begin{column}{.1\linewidth}
				\begin{figure}
					\centering
					\includegraphics[width=0.9\linewidth]{pictures/big-arrow}
				\end{figure}
			\end{column}
			\begin{column}{.5\linewidth}
				\begin{figure}
					\centering
					\includegraphics[width=0.9\linewidth]{pictures/drqn-architecture}
				\end{figure}
				
			\end{column}
		\end{columns}
	\end{frame}

	\begin{frame}{Deep Recurrent Q-Network}
		\begin{columns}
			\begin{column}{.6\linewidth}
				ä¸DQNç›¸æ¯”ï¼ŒDRQN:
				\begin{itemize}
					\item å°†åŸæœ¬çš„å…¨è¿æ¥å±‚æ›¿æ¢ä¸ºç›¸åŒç»´åº¦çš„Long-Short Term Memory (LSTM).
					
					\item æ¯ä¸€ä¸ªtimestepåªæ¥å—ä¸€å¸§ç”»é¢ä½œä¸ºè¾“å…¥ã€‚
					
					\item LSTMä¸ºè¿‡å»çš„çŠ¶æ€æä¾›è®°å¿†èƒ½åŠ›ã€‚
					
				\end{itemize}
			\end{column}
			\begin{column}{.4\linewidth}
				\begin{figure}
					\centering
					\includegraphics[width=0.9\linewidth]{pictures/drqn-architecture}
					\caption{}
					\label{fig:drqn-architecture}
				\end{figure}
				
			\end{column}
		\end{columns}
	\end{frame}

	\begin{frame}{Research Line}
		\begin{itemize}
			\item Intelligent decision making is the heart of AI.
			
			\item Desire agents capable of learning to act intelligently in diverse environments.
			
			\item Reinforcement learning provides a general learning framework.
			
			\item RL + deep neural networks yields robust controllers that learn from pixels. (DQN)
			
			\item DQN lacks mechanisms for handling partial observability.
			
			\item Extend DQN to handle Partially Observable Markov Decision Processes (POMDPs).
			
		\end{itemize}
	\end{frame}

	\begin{frame}{DRQN}{å®éªŒï¼šDRQN vs DQN}
		\begin{itemize}
			\item æ¯”è¾ƒå¯¹è±¡ï¼š
				\begin{itemize}
					\item DRQNï¼›
					\item æ‰©å±•DQNï¼ˆå°†æ™®é€šDQNçš„è¾“å…¥æ‰©å±•åˆ°10å¼ å›¾ç‰‡ï¼‰ï¼›
					\item DQN.
				\end{itemize}
			
			\item å®éªŒç›®æ ‡ï¼š
				\begin{itemize}
					\item Standard Atari games
					\item Flickering Atari games
				\end{itemize}
			
		\end{itemize}
	\end{frame}

	\begin{frame}{DRQN vs DQN}{å®éªŒç»“æœ}
		\begin{figure}
			\centering
			\includegraphics[width=0.9\linewidth]{pictures/dqn-vs-drqn-result}
			\caption{DRQNçš„è¡¨ç°å‹‰å¼ºè¾¾åˆ°DQNçš„æ°´å¹³}
			\label{fig:dqn-vs-drqn-result}
		\end{figure}
		
	\end{frame}

	\begin{frame}{DRQN}{Flickering Atari games}
		\begin{columns}
			\begin{column}{.6\linewidth}
				ä»¥ä¸€ä¸ªéšæœºæ¦‚ç‡é®è”½å±å¹•ï¼Œä½¿æ¸¸æˆå‘ˆç°partially observability.
				%è¿™ä¸ªå…¬å¼æ˜¯å“ªé‡Œæ¥çš„ï¼Ÿ
				\[o_t
					\begin{cases}
						s_t & with p = \frac{1}{2} \\
						\langle 0, \dots, 0 \rangle & \text{otherwise}
					\end{cases}
				\]
				
				ç°åœ¨ï¼Œå½“å‰çš„æ¸¸æˆçŠ¶æ€åªèƒ½å¤Ÿä»å†å²çŠ¶æ€ä¸­è·å–åˆ°äº†ã€‚
			\end{column}
		
			\begin{column}{.4\linewidth}
				\begin{figure}
					\centering
					\includegraphics[width=0.7\linewidth]{pictures/pomdp}
				\end{figure}
			\end{column}
		\end{columns}
	\end{frame}

	\begin{frame}{DRQN}{Results: Flickering Atari games}
		\begin{figure}
			\centering
			\includegraphics[width=0.7\linewidth]{pictures/flickering-atari-result}
			\caption{æ¨ªè½´ï¼šæŸæ—¶é—´æ­¥èƒ½å¤Ÿè§‚æµ‹åˆ°æ¸¸æˆç”»é¢çš„æ¦‚ç‡ï¼›çºµè½´ï¼šå„æ¨¡å‹ä¸è‡ªå·±Standard Atari gameså¾—åˆ†çš„æ¯”å€¼}
			\label{fig:flickering-atari-result}
		\end{figure}
		
	\end{frame}

	\begin{frame}{DRQN}{ç»“è®º}
		\begin{itemize}
				\item åœ¨Standard Atari gamesä¸­ï¼ŒDRQNçš„è¡¨ç°å‹‰å¼ºæ¯”ä¸ŠDQN
				\item åœ¨Flickering Atari gameä¸­ï¼ŒDRQNè¡¨ç°ä¸‹é™çš„å¹…åº¦æ¯”DQNå°å¾—å¤š
		\end{itemize}
	
		\visible<2->{ä½†è¿™æ ·çš„ç»“æœè¿œè¿œä¸èƒ½è®©äººæ»¡æ„â€¦â€¦}
	\end{frame}
	
	\section{ç”¨DRQNç©FPSæ¸¸æˆ}

	\begin{frame}{DRQN for FPS}{}
		FPSå³ç¬¬ä¸€äººç§°å°„å‡»æ¸¸æˆ(First person shooting games)ï¼Œä¸Atari 2600ç›¸æ¯”ï¼ŒFPSæ¸¸æˆå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š
	
		\begin{itemize}
			\item æ“ä½œæ›´åŠ å¤æ‚ï¼Œè¡Œä¸ºæ›´åŠ ä¸°å¯Œ(æœç´¢åœ°å›¾ï¼Œæ”¶é›†é“å…·ï¼Œè¯†åˆ«å¹¶æ‰“è´¥æ•Œäººâ€¦)ï¼›
			\item ç”»é¢åªèƒ½è§‚æµ‹åˆ°éƒ¨åˆ†æ¸¸æˆçŠ¶æ€(partially observable)ï¼›
			\item FPSä¸ç°å®åœºæ™¯ç›¸ä¼¼ï¼Œç›¸å…³æŠ€æœ¯é€‚åˆåœ¨æœºå™¨äººå¼€å‘ä¸­å¾—åˆ°åº”ç”¨ã€‚
		\end{itemize}
	\end{frame}

	\begin{frame}{DRQN for FPS}{VizDoom}
		VizDoomæ˜¯ä¸€ä¸ªåŸºäºDoomçš„AIç ”ç©¶å¹³å°ï¼Œä¸»è¦é’ˆå¯¹é¢å‘åŸå§‹è§†è§‰ä¿¡æ¯è¾“å…¥çš„å¢å¼ºå­¦ä¹ ã€‚
		
		Doom Deathmatchè§„åˆ™ä»‹ç»ï¼š
		http://vizdoom.cs.put.edu.pl/
		
		\begin{figure}
			\centering
			\includegraphics[width=0.8\linewidth]{pictures/deathmatch}
		\end{figure}
	\end{frame}

	\begin{frame}{DRQN for FPS}{Baseline DRQN model}
		é¦–å…ˆï¼Œç›´æ¥åˆ©ç”¨åŸå§‹çš„DRQNè¿ç”¨åœ¨ViZDoomä¸Šï¼Œæ•ˆæœå¹¶ä¸å¥½ã€‚
		\begin{itemize}
			\item è®­ç»ƒå‡ºçš„agentä¼šéšæ„å¼€ç«ï¼›
			\item å¯¹ä½¿ç”¨å¼¹è¯åŠ ä»¥æƒ©ç½šï¼šå¦‚æœæƒ©ç½šè¿‡é‡ï¼Œagentå°±ä¸ä¼šå¼€ç«ï¼›è¿‡è½»ï¼Œagentä¾ç„¶ä¼šéšæ„å¼€ç«ã€‚
			\item agentä¸èƒ½å¤Ÿå‡†ç¡®åœ°æ¢æµ‹æ•Œäºº
		\end{itemize}
		
	\end{frame}

	\begin{frame}{DRQN for FPS}{Methods}
		\begin{description}
			\item[DRQN augmented with game features] 
			ä½¿ç”¨äº†ä¸€ä¸ªå¢åŠ æ¸¸æˆä¿¡æ¯(game features)çš„DRQNæ¨¡å‹æ¥æå‡æ€§èƒ½ã€‚
			
			\item[Divide and conquer]
			å°†æ¸¸æˆè¿‡ç¨‹åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µåˆ†åˆ«è®­ç»ƒï¼Œæå‡æ€§èƒ½å¹¶åŠ å¿«äº†è®­ç»ƒé€Ÿåº¦ã€‚
			
		\end{description}
	\end{frame}

	\begin{frame}{Methods}{DRQN augmented with game features-I}
		\begin{figure}
			\centering
			\includegraphics[width=0.7\linewidth]{pictures/drqn-with-game-features}
		\end{figure}
		
	\end{frame}

	\begin{frame}{Methods}{DRQN augmented with game features-II}
		\begin{itemize}
			\item è®­ç»ƒæ—¶åŠ å…¥äº†å½“å‰ç”»é¢çš„æ¸¸æˆçŠ¶æ€ä¿¡æ¯ä½œä¸ºè¾“å…¥;
			
			\item ç½‘ç»œçš„æŸå¤±å‡½æ•°æ˜¯DRQNçš„æŸå¤±å‡½æ•°åˆå¹¶ä¸Šäº¤å‰ç†µæŸå¤±(cross-entropy loss)ï¼ŒåŒæ—¶è®­ç»ƒDRQNå’Œæ¸¸æˆçŠ¶æ€ä¿¡æ¯çš„ä¾¦æµ‹ï¼Œä½¿å·ç§¯å±‚ä¹Ÿèƒ½å¤Ÿæ•æ‰åˆ°ä¸æ¸¸æˆç›¸å…³çš„ä¿¡æ¯;
			
			\item è™½ç„¶å¯ä»¥è·å¾—è®¸å¤šæ¸¸æˆä¿¡æ¯ï¼Œä½†ä»…è€ƒè™‘ç”»é¢ä¸­æ˜¯å¦æœ‰æ•Œäººçš„ä¿¡æ¯ï¼Œå°±èƒ½ä½¿æ¨¡å‹çš„è¡¨ç°æœ‰æ˜¾è‘—çš„æ”¹è¿›ã€‚
		\end{itemize}
	\end{frame}

	\begin{frame}{Methods}{With vs without game features}
		\begin{figure}
			\centering
			\includegraphics[width=0.7\linewidth]{pictures/with-game-features-result}
			\caption{æ¨ªè½´ï¼šè®­ç»ƒæ—¶é—´ï¼›çºµè½´ï¼šå‡»æ€æ­»äº¡æ¯”}
			\label{fig:with-game-features-result}
		\end{figure}
	\end{frame}

	\begin{frame}{Methods}{Divide and conquer-é˜¶æ®µåˆ’åˆ†}
		Doom Deathmatch æ¸¸æˆè¿‡ç¨‹è¢«åˆ†æˆä¸¤ä¸ªé˜¶æ®µï¼šå¯¼èˆªé˜¶æ®µå’Œè¡ŒåŠ¨é˜¶æ®µ
		\begin{description}
			\item[å¯¼èˆªé˜¶æ®µ(the navigation)]  æ¢ç´¢åœ°å›¾ï¼Œæ”¶é›†ï¼Œå‘ç°æ•Œäºº
			\item[è¡ŒåŠ¨é˜¶æ®µ(the action)]ï¼šæ”»å‡»æ•Œäºº
		\end{description}
		
		\visible<2->{	
			å½“å‰æ¸¸æˆè¿‡ç¨‹å¤„ä½•é˜¶æ®µç”±ç”»é¢ä¸­æ˜¯å¦æœ‰æ•Œäººæ¥å†³å®š(game feature)ã€‚
		}
	
	\end{frame}

	\begin{frame}{Methods}{Divide and conquer-é˜¶æ®µç¤ºä¾‹}
		\begin{columns}
			\begin{column}{.5\linewidth}
				\begin{figure}
					\centering
					\includegraphics[width=0.9\linewidth]{pictures/deathmatch-2}
					\caption{å¯¼èˆªé˜¶æ®µ}
					\label{fig:deathmatch-2}
				\end{figure}
			\end{column}
			\begin{column}{.5\linewidth}
				\begin{figure}
					\centering
					\includegraphics[width=0.9\linewidth]{pictures/deathmatch-3}
					\caption{è¡ŒåŠ¨é˜¶æ®µ}
					\label{fig:deathmatch-3}
				\end{figure}
				
			\end{column}
		\end{columns}
	\end{frame}

	\begin{frame}{Methods}{Divide and conquer-è®­ç»ƒæ¨¡å‹}
		å¯¹ä¸åŒçš„é˜¶æ®µï¼Œä½¿ç”¨äº†ä¸åŒçš„æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼š
		\begin{description}
			\item[å¯¼èˆªé˜¶æ®µ] DQN
			\item[è¡ŒåŠ¨é˜¶æ®µ] DRQN with game features
		\end{description}
		
		\visible<2->{
			ç›®å‰ï¼ŒDQNå¹¶ä¸æ”¯æŒç»“åˆå¤šä¸ªç½‘ç»œæ¥ä¼˜åŒ–ä¸åŒçš„ç›®æ ‡ï¼Œä½†å½“å‰çš„æ¸¸æˆä¿¡æ¯å¯ä»¥ç”±æ”¹è¿›çš„DRQNè¿›è¡Œä¾¦æµ‹ã€‚
		}
		
	\end{frame}

	\begin{frame}{Methods}{Divide and conquer-ä¼˜ç‚¹}
		è¿™æ ·çš„åˆ†æ²»ç­–ç•¥å¸¦æ¥è®¸å¤šä¼˜ç‚¹ï¼š
		\begin{itemize}
			\item<2-> ä¸¤ä¸ªç½‘ç»œå¯ä»¥å¹¶è¡Œè®­ç»ƒï¼Œå¤§å¤§åŠ å¿«äº†æ¨¡å‹è®­ç»ƒé€Ÿåº¦ã€‚
			\item<3-> å¯¼èˆªé˜¶æ®µåªåŒ…å«äº†ä¸‰ç§æ“ä½œï¼šå‘å·¦ã€å‘å³å’Œå‰è¿›ï¼Œå¤§å¤§å‡å°‘äº†æ¨¡å‹ä¸­state-action pairsçš„æ•°é‡ï¼Œè¿›ä¸€æ­¥æé«˜æ•ˆç‡ã€‚
			\item<4-> ç›¸æ¯”ä½¿ç”¨å•ä¸ªç½‘ç»œè®­ç»ƒï¼Œåˆ†æ²»æœ‰æ•ˆé¿å…äº†agentçš„â€œè¹²ç‚¹â€è¡Œä¸ºã€‚
			
		\end{itemize}
	\end{frame}

	\begin{frame}{Divide and conquer}{Training: Reward shaping}
		åœ¨Doom deathmatchä¸­ï¼Œæ¸¸æˆåˆ†æ•°é€šè¿‡ å‡»æ€æ•°/æ­»äº¡æ•°(K/D ratio) è¿›è¡Œè®¡ç®—ã€‚å¦‚æœå›é¦ˆåªé€šè¿‡è®¡ç®—åˆ†æ•°å¾—åˆ°ï¼Œé‚£ä¹ˆDRQNè®­ç»ƒæ—¶çš„replay tableä¼šéå¸¸ç¨€ç–ï¼Œå¯¼è‡´æ¨¡å‹åœ¨è®­ç»ƒæ—¶éš¾ä»¥æ”¶æ•›ã€‚
		
		ä½œè€…ä»¬é‡‡å–äº†å›é¦ˆå…±äº«(Reward shaping)çš„æ€è·¯ï¼Œä¿®æ”¹å›æŠ¥å‡½æ•°ï¼ŒåŒ…å«ä¸€äº›å°çš„ä¸­é—´å›æŠ¥æ¥åŠ é€Ÿå­¦ä¹ è¿‡ç¨‹ã€‚
		
	\end{frame}

	\begin{frame}{Divide and conquer}{Training: Reward shaping-åŸºæœ¬åŸåˆ™}
		åŸºäºå‡»æ€ç»™äºˆæ­£å›é¦ˆï¼Œæ­»äº¡åŸºäºè´Ÿå›é¦ˆçš„åŸºç¡€ä¸Šï¼Œå¢åŠ äº†ä»¥ä¸‹ä¸­é—´å›é¦ˆ
		\begin{description}
			\item[è¡ŒåŠ¨ç½‘ç»œ] 
				\begin{itemize}
					\item æ‹¾å–ç‰©å“ï¼Œæ­£å›é¦ˆ
					\item å¤±å»ç”Ÿå‘½å€¼ï¼Œè´Ÿå›é¦ˆ
					\item å¼€æªå°„å‡»å¯¼è‡´å¼¹è¯å‡å°‘ï¼Œè´Ÿå›é¦ˆ
				\end{itemize}
			\item [å¯¼èˆªç½‘ç»œ]
				\begin{itemize}
					\item æ‹¾å–ç‰©å“ï¼Œæ­£å›é¦ˆ
					\item åœ¨å²©æµ†ä¸Šè¡Œèµ°ï¼Œè´Ÿå›é¦ˆ
					\item ç§»åŠ¨è·ç¦»ï¼Œæ­£å›é¦ˆ  â€”â€”æœ‰åˆ©äºè®©agentæ›´å¿«é€Ÿåœ°æ¢ç´¢åœ°å›¾
				\end{itemize}
		\end{description}
	\end{frame}

	\begin{frame}{Experiments: Visual Doom AI Competition}{èµ›åˆ¶}
		èµ›åˆ¶åˆ†ä¸¤ç§ï¼š
		\begin{itemize}
			\item å·²çŸ¥åœ°å›¾ä¸Šçš„å—é™åˆ¶æ­»äº¡ç«èµ›(Limited Deathmatch)ï¼šæ­¦å™¨åªæœ‰ç«ç®­ç‚®ï¼Œagentå¯ä»¥æ¡è¡€åŒ…å’Œå¼¹è¯ï¼›
			
			\item æœªçŸ¥åœ°å›¾ä¸Šçš„çš„æ— é™åˆ¶æ­»äº¡ç«èµ›(Limited Deathmatch)ï¼šagentåˆå§‹åªæœ‰æ‰‹æªï¼Œå¯ä»¥æ¡å„ç§æ­¦å™¨å¼¹è¯å’Œè¡€åŒ…ã€‚æä¾›äº†ä¸¤å¼ åœ°å›¾ç”¨äºè®­ç»ƒï¼Œ3å¼ æœªçŸ¥åœ°å›¾ç”¨äºæµ‹è¯•ã€‚
		\end{itemize}
	\end{frame}

	\begin{frame}{å®éªŒç»“æœ}{Performance of the agent with/without navigation}
		\begin{figure}
			\centering
			\includegraphics[width=0.9\linewidth]{pictures/fps-exper-result-1}
		\end{figure}
	\end{frame}

	\begin{frame}{å®éªŒç»“æœ}{Visual Doom AI Competition @ CIG 2016}
		\begin{figure}
			\centering
			\includegraphics[width=0.9\linewidth]{pictures/fps-exper-result-2}
		\end{figure}
		\begin{figure}
			\centering
			\includegraphics[width=0.9\linewidth]{pictures/fps-exper-result-3}
		\end{figure}
	\end{frame}

	\begin{frame}{å®éªŒç»“æœ}{Comparison of human players with agent}
		\begin{columns}
			\begin{column}{.5\linewidth}
				\begin{description}
					\item[Single player] äººç±»å’Œagentåˆ†åˆ«åœ¨ç‹¬ç«‹çš„æ¸¸æˆä¸­ä¸æœºå™¨äººè¾ƒé‡
					
					\item[Multiplayer] äººç±»ä¸agentç›¸äº’åˆ‡ç£‹
					
				\end{description}
			\end{column}
			\begin{column}{.5\linewidth}
				\begin{figure}
					\centering
					\includegraphics[width=0.9\linewidth]{pictures/fps-exper-result-4}
					\caption{}
					\label{fig:fps-exper-result-4}
				\end{figure}
			\end{column}
		\end{columns}
	\end{frame}

	\begin{frame}{å®éªŒç»“æœ}{2017 Competition Results}
		\begin{figure}
			\centering
			\includegraphics[width=0.9\linewidth]{pictures/fps-exper-result-5}
		\end{figure}
		
		\begin{figure}
			\centering
			\includegraphics[width=0.9\linewidth]{pictures/fps-exper-result-6}
		\end{figure}
	\end{frame}
		
	\section*{å‚è€ƒæ–‡çŒ®}
	
	\begin{frame}{å‚è€ƒæ–‡çŒ®}
		\bibliographystyle{apalike}
		\bibliography{reference}
	\end{frame}
	
	{\background%æœ«é¡µè‡´è°¢
		\begin{frame}[plain,noframenumbering]
			\finalpage{{\huge æ„Ÿè°¢è§‚çœ‹ï¼\\ \small Q \& A}}
		\end{frame}
	}
	
\end{document}